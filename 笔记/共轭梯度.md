# 共轭梯度



## 思想

虽然梯度下降法的每一步都是朝着局部最优的方向前进的，但是**它在不同的迭代轮数中会选择非常近似的方向，说明这个方向的误差并没通过一次更新方向和步长更新完，在这个方向上还存在误差**，因此参数更新的轨迹是锯齿状。

共轭梯度法的思想是，**选择一个优化方向后，本次选择的步长能够将这个方向的误差更新完，在以后的优化更新过程中不再需要朝这个方向更新了。由于每次将一个方向优化到了极小，后面的优化过程将不再影响之前优化方向上的极小值，所以理论上对N维问题求极小只用对N个方向都求出极小就行了**。为了不影响之前优化方向上的更新量，需要每次优化方向共轭正交。假定**每一步的优化方向用p<sub>k</sub>**表示，可得共轭正交

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003201524941.png" alt="image-20201003201524941" style="zoom:67%;" />

由此可得，每一步优化后，当前的误差和刚才的优化方向共轭正交。

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003201432052.png" alt="image-20201003201432052" style="zoom:67%;" />

若为N维空间优化问题，则每次优化方向可以组成这个空间中的一组基底。

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003201354345.png" alt="image-20201003201354345" style="zoom:67%;" />

***

## 优化问题

假定待优化的问题如下所示：

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003211240349.png" alt="image-20201003211240349" style="zoom:67%;" />

其中*x*为待优化变量，*A*为半正定矩阵（在线性代数中，正定矩阵为对称矩阵），*b*为已知变量。下标k表示优化步数，负梯度为

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003211304998.png" alt="image-20201003211304998" style="zoom:80%;" />

假设最优变量为x<sup>∗</sup>，则优化问题可变为求方程*A*x<sup>*</sup> =b的解。梯度r也可以称作每一步的残差。误差定义为x与最优变量的差值

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003211654188.png" alt="image-20201003211654188" style="zoom:80%;" />

***

### 优化方向确定

假定第一次优化方向为初始负梯度方向

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003211752066.png" alt="image-20201003211752066" style="zoom:80%;" />

每一次优化方向与之前的优化方向正交，采用Gram-Schmidt方法进行向量正交化，每次优化方向根据当前步的梯度得出

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003211827105.png" alt="image-20201003211827105" style="zoom:80%;" />

令

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003211933222.png" alt="image-20201003211933222" style="zoom:80%;" />

***

### 优化步长确定

假定第k步的优化步长为α<sub>k</sub>:

![image-20201003212933057](C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201003212933057.png)

***

## 推论

* 第k步计算的梯度r<sub>k</sub>和前k-1步的优化向量{p<sub>i</sub>}<sub>i=1</sub><sup>k-1</sup>正交
* 第k步计算的梯度r<sub>k</sub>和前k-1步的梯度{r<sub>i</sub>}<sub>i=1</sub><sup>k-1</sup>正交
* 第k步计算的梯度r<sub>k</sub>和前k-2步的优化向量{p<sub>i</sub>}<sub>i=1</sub><sup>k-2</sup>共轭正交

***

## 简化

### 优化方向简化

由推论三可得

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201004103152150.png" alt="image-20201004103152150" style="zoom:80%;" />

### 优化步长简化

第三个等式引用推论一

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201004103346025.png" alt="image-20201004103346025" style="zoom:80%;" />

### 梯度计算简化

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201004103414936.png" alt="image-20201004103414936" style="zoom:80%;" />

## 伪代码

<img src="C:\Users\26082\AppData\Roaming\Typora\typora-user-images\image-20201004103449156.png" alt="image-20201004103449156" style="zoom:80%;" />