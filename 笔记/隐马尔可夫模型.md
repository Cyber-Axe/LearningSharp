# 隐马尔可夫模型



## 简介

使用HMM模型时的问题一般有两个特征：

１）问题是**基于序列**的，比如时间序列，或者状态序列。

２）我们的问题中有两类数据，一类序列数据是可以观测到的，即**观测序列**；而另一类数据是不能观察到的，即**隐藏状态序列**，简称状态序列。有了这两个特征，那么这个问题一般可以用HMM模型来尝试解决。可见状态之间没有转换概率，但是隐含状态和可见状态之间有一个概率叫做输出概率（emission probability）



任何一个HMM都可以通过下列五元组来描述：

```html
:param obs:观测序列
:param states:隐状态
:param start_p:初始概率（隐状态）
:param trans_p:转移概率（隐状态）
:param emit_p: 发射概率 （隐状态表现为显状态的概率）
```

[![6cbb8645gw1egs40a3bpmj208n09574o](https://images0.cnblogs.com/blog/133059/201507/161450536414597.jpg)](http://images0.cnblogs.com/blog/133059/201507/161450524231771.jpg)



## 定义

Q是所有可能的隐藏状态的集合，V是所有可能的观测状态的集合，即

![Q = \{q_1,q_2,...,q_N\}, \; V =\{v_1,v_2,...v_M\}](https://private.codecogs.com/gif.latex?Q%20%3D%20%5C%7Bq_1%2Cq_2%2C...%2Cq_N%5C%7D%2C%20%5C%3B%20V%20%3D%5C%7Bv_1%2Cv_2%2C...v_M%5C%7D)

其中，N是可能的隐藏状态数，M是所有的可能的观察状态数。对于一个长度为T的序列，I对应的隐藏状态序列, O是对应的观察序列，即：

![I = \{i_1,i_2,...,i_T\}, \; O =\{o_1,o_2,...o_T\}](https://private.codecogs.com/gif.latex?I%20%3D%20%5C%7Bi_1%2Ci_2%2C...%2Ci_T%5C%7D%2C%20%5C%3B%20O%20%3D%5C%7Bo_1%2Co_2%2C...o_T%5C%7D)

其中，任意一个隐藏状态 ![i_t \in Q](https://private.codecogs.com/gif.latex?i_t%20%5Cin%20Q)，任意一个观察状态 ![o_t \in V](https://private.codecogs.com/gif.latex?o_t%20%5Cin%20V)

![img](https://img-blog.csdnimg.cn/2019040512514457.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW5nNDI1Nzc2MDI0,size_16,color_FFFFFF,t_70)



## 重点假设

HMM模型的两个重要假设：

+ **齐次马尔科夫链假设**。即任意时刻的隐藏状态只依赖于它前一个隐藏状态，这样假设有点极端，因为很多时候我们的某一个隐藏状态不仅仅只依赖于前一个隐藏状态，可能是前两个或者是前三个。但是这样假设的好处就是模型简单，便于求解。如果在时刻t的隐藏状态是![i_t= q_i](https://private.codecogs.com/gif.latex?i_t%3D%20q_i)，在时刻t+1的隐藏状态是![i_{t+1} = q_j](https://private.codecogs.com/gif.latex?i_%7Bt&plus;1%7D%20%3D%20q_j)，则从时刻t到时刻t+1的HMM状态转移概率![a_{ij}](https://private.codecogs.com/gif.latex?a_%7Bij%7D)可表示为：

  ![a_{ij} = P(i_{t+1} = q_j | i_t= q_i)](https://private.codecogs.com/gif.latex?a_%7Bij%7D%20%3D%20P%28i_%7Bt&plus;1%7D%20%3D%20q_j%20%7C%20i_t%3D%20q_i%29)，

  ![img](https://img-blog.csdnimg.cn/20190405162844252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW5nNDI1Nzc2MDI0,size_16,color_FFFFFF,t_70)

  这样![a_{ij}](https://private.codecogs.com/gif.latex?a_%7Bij%7D)可以组成马尔科夫链的状态转移矩阵A:

  ![A=\Big [a_{ij}\Big ]_{N \times N}](https://private.codecogs.com/gif.latex?A%3D%5CBig%20%5Ba_%7Bij%7D%5CBig%20%5D_%7BN%20%5Ctimes%20N%7D)（状态集Q有N个不同的状态，任意一个之间都可能状态转移，所以是NxN）

+  **观测独立性假设**。即任意时刻的观察状态只仅仅依赖于当前时刻的隐藏状态，这也是一个为了简化模型的假设。如果在时刻t的隐藏状态是![i_t= q_j](https://private.codecogs.com/gif.latex?i_t%3D%20q_j)，而对应的观察状态为 ![o_t = v_k](https://private.codecogs.com/gif.latex?o_t%20%3D%20v_k)，则该时刻观察状态![v_k](https://private.codecogs.com/gif.latex?v_k)在隐藏状态![q_j](https://private.codecogs.com/gif.latex?q_j)下生成的概率为![b_j(k)](https://private.codecogs.com/gif.latex?b_j%28k%29),满足：![b_j(k) = P(o_t = v_k | i_t= q_j)](https://private.codecogs.com/gif.latex?b_j%28k%29%20%3D%20P%28o_t%20%3D%20v_k%20%7C%20i_t%3D%20q_j%29)

  <img src="https://img-blog.csdnimg.cn/2019040516300186.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW5nNDI1Nzc2MDI0,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />

  则![b_j(k)](https://private.codecogs.com/gif.latex?b_j%28k%29)可以组成观测状态生成的概率矩阵B:

  ![B = \Big [b_j(k) \Big ]_{N \times M}](https://private.codecogs.com/gif.latex?B%20%3D%20%5CBig%20%5Bb_j%28k%29%20%5CBig%20%5D_%7BN%20%5Ctimes%20M%7D),(N个不同的状态的任意一个都可能生成观测集V中M个的任意一个观测状态，所以是NxM)

  除此之外，我们需要一组在时刻t=1的隐藏状态概率分布Π

  ![\Pi = \Big [ \pi(i)\Big ]_N \; 其中 \;\pi(i) = P(i_1 = q_i)](https://private.codecogs.com/gif.latex?%5CPi%20%3D%20%5CBig%20%5B%20%5Cpi%28i%29%5CBig%20%5D_N%20%5C%3B%20%25u5176%25u4E2D%20%5C%3B%5Cpi%28i%29%20%3D%20P%28i_1%20%3D%20q_i%29)其中![\;\pi(i) = P(i_1 = q_i)](https://private.codecogs.com/gif.latex?%5C%3B%5Cpi%28i%29%20%3D%20P%28i_1%20%3D%20q_i%29),（状态集合Q中N个状态的概率）

  一个HMM模型，可以由隐藏状态初始概率分布Π, 状态转移概率矩阵A和观测状态概率矩阵B决定。Π,A决定状态序列，B决定观测序列。因此，HMM模型可以由一个三元组λ表示如下：

  ![\lambda = (A, B, \Pi)](https://private.codecogs.com/gif.latex?%5Clambda%20%3D%20%28A%2C%20B%2C%20%5CPi%29)

## 算法举例

**知道骰子有几种（隐含状态数量），不知道每种骰子是什么（转换概率），观测到很多次掷骰子的结果（可见状态链），我想反推出每种骰子是什么（转换概率）**。
   这个问题很重要，因为这是最常见的情况。很多时候我们只有可见结果，不知道HMM模型里的参数，我们需要从可见结果估计出这些参数，这是建模的一个必要步骤。